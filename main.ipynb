{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5504,"status":"ok","timestamp":1679769741812,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"a5wk81SB3LCK","outputId":"6100413b-fa7f-4adc-cd08-c02d8b4a42d7"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["import warnings\n","import pip\n","import site\n","import importlib\n","\n","with warnings.catch_warnings():\n","    warnings.simplefilter(\"ignore\")\n","    libs = ['transformers', 'datasets', 'numpy', 'pandas', 'torch']\n","    for lib in libs:\n","        pip.main(['install', '--disable-pip-version-check', '-q', lib])\n","    importlib.reload(site)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["import torch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","os.environ[\"HF_HOME\"] = \"/output/\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":925,"status":"ok","timestamp":1679769742722,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"YUxTwMvU3Gdr","outputId":"47c588b1-877d-4ac1-9b59-6aa33d26a57d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","\rDownloading readme:   0%|          | 0.00/493 [00:00<?, ?B/s]\rDownloading readme: 100%|██████████| 493/493 [00:00<00:00, 237kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset None/None to /home/coder/.cache/huggingface/datasets/under-tree___parquet/under-tree--labeled-multiple-choice-8214d50786758969/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]\n","\rDownloading data:   0%|          | 0.00/1.29M [00:00<?, ?B/s]\u001b[A\rDownloading data: 100%|██████████| 1.29M/1.29M [00:00<00:00, 76.7MB/s]\n","\rDownloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\rDownloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n","\rExtracting data files:   0%|          | 0/1 [00:00<?, ?it/s]\rExtracting data files: 100%|██████████| 1/1 [00:00<00:00, 1169.63it/s]\n","\rGenerating train split:   0%|          | 0/36503 [00:00<?, ? examples/s]\r                                                                        "]},{"name":"stdout","output_type":"stream","text":["Dataset parquet downloaded and prepared to /home/coder/.cache/huggingface/datasets/under-tree___parquet/under-tree--labeled-multiple-choice-8214d50786758969/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"]},{"name":"stderr","output_type":"stream","text":["\r"]}],"source":["from datasets import load_dataset\n","data = load_dataset('under-tree/labeled-multiple-choice', split='train')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1679769742723,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"p-YJCYkA3Gdw","outputId":"468661a1-4377-4f2f-824f-e1df0166524f"},"outputs":[{"name":"stdout","output_type":"stream","text":["''\n"]}],"source":["from pprint import pprint\n","pprint('')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1679769742723,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"xBL7_fga3Gdw","outputId":"4aeb9270-5c46-4460-e448-4df7e2b299b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["question: what type of water formation is formed by clouds? (a) pearls (b) streams (c) shells (d) diamonds (e) rain (f) beads (g) cooled (h) liquid\n","answer: f\n","context: beads of water can be formed by clouds.\n","\n"]}],"source":["def gen_prompt(elem):\n","    # return f'question: {elem.formatted_question}\\nanswer: {elem.answerKey}\\ncontext: {elem.combinedfact}\\n'\n","    # dict \n","    return {'text': f'question: {elem[\"formatted_question\"]}\\nanswer: {elem[\"answerKey\"]}\\ncontext: {elem[\"combinedfact\"]}\\n'}\n","print(gen_prompt(data[0])['text'])"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1679769742723,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"J_WR3_El3Gdx","outputId":"8efc4ca7-e1de-46a0-dcd0-27f985ceab9c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Map (num_proc=4):   0%|          | 0/36503 [00:00<?, ? examples/s]\rMap (num_proc=4):  11%|█         | 4079/36503 [00:00<00:01, 30597.89 examples/s]\rMap (num_proc=4):  27%|██▋       | 9929/36503 [00:00<00:00, 42455.44 examples/s]\rMap (num_proc=4):  44%|████▍     | 16117/36503 [00:00<00:00, 50374.79 examples/s]\rMap (num_proc=4):  63%|██████▎   | 22869/36503 [00:00<00:00, 56640.19 examples/s]\rMap (num_proc=4):  81%|████████  | 29592/36503 [00:00<00:00, 60185.24 examples/s]\rMap (num_proc=4): 100%|█████████▉| 36338/36503 [00:00<00:00, 62500.56 examples/s]\r                                                                                 \r"]}],"source":["data_with_prompt = data.map(gen_prompt, batched=False, remove_columns=data.column_names, num_proc=4)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3259,"status":"ok","timestamp":1679769745976,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"KIImvYJY3Gdy","outputId":"54864c10-5fb6-486f-bab6-3c8dece3aeff"},"outputs":[{"name":"stderr","output_type":"stream","text":["None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n","\rDownloading (…)lve/main/config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]\rDownloading (…)lve/main/config.json: 100%|██████████| 762/762 [00:00<00:00, 109kB/s]\n","\rDownloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]\rDownloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.48MB/s]\rDownloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.47MB/s]\n","\rDownloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]\rDownloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.31MB/s]\rDownloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.30MB/s]\n","\rDownloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]\rDownloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 1.79MB/s]\rDownloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 1.78MB/s]\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"ename":"ImportError","evalue":"\nAutoModelForCausalLM requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn [6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m special_tokens \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39madditional_special_tokens\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mquestion: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39manswer: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcontext: \u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m      6\u001b[0m tokenizer\u001b[39m.\u001b[39madd_special_tokens(special_tokens)\n\u001b[0;32m----> 8\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(checkpoint)\n\u001b[1;32m      9\u001b[0m model\u001b[39m.\u001b[39mresize_token_embeddings(\u001b[39mlen\u001b[39m(tokenizer))\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/utils/import_utils.py:1066\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_from_config\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1065\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1066\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/utils/import_utils.py:1054\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1052\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[1;32m   1053\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[0;32m-> 1054\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n","\u001b[0;31mImportError\u001b[0m: \nAutoModelForCausalLM requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","checkpoint = 'distilgpt2'\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint, pad_token='<|pad|>', use_fast=True)\n","special_tokens = {'additional_special_tokens': ['question: ', 'answer: ', 'context: ']}\n","tokenizer.add_special_tokens(special_tokens)\n","\n","model = AutoModelForCausalLM.from_pretrained(checkpoint)\n","model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1679769745976,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"SJWHv5Vm3Gdy","outputId":"7728867c-171e-4203-8d4a-7c3e806f72c6"},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[50258, 10919,  2099,   286,  1660,  9978,   318,  7042,   416, 15114,\n","            30,   357,    64,     8, 25286,  7278,   357,    65,     8, 15190,\n","           357,    66,     8, 19679,   357,    67,     8, 30984,   357,    68,\n","             8,  6290,   357,    69,     8, 36116,   357,    70,     8, 32162,\n","           357,    71,     8,  8122,   198, 50259,    69,   198, 50260,    65,\n","          1329,    82,   286,  1660,   460,   307,  7042,   416, 15114,    13,\n","           198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer(data_with_prompt[0]['text'], return_tensors='pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1679769745977,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"INYCseTK3Gdz","outputId":"a5052315-72e4-426c-df4c-19bcb8494c7c"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/under-tree___parquet/under-tree--labeled-multiple-choice-8214d50786758969/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-fc8b2636c5e92eb8.arrow\n"]},{"name":"stdout","output_type":"stream","text":["Max:  738\n"]}],"source":["mx = max(map(len, data_with_prompt['text']))\n","print('Max: ', mx)\n","\n","def encode(elem):\n","    return tokenizer(elem['text'], truncation=True)\n","\n","data_encoded = data_with_prompt.map(encode, batched=True, remove_columns=data_with_prompt.column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1679769745977,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"GLWnTY9q3Gdz"},"outputs":[],"source":["block_size = 128\n","\n","def group_texts(examples):\n","    # Concatenate all texts.\n","    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n","    total_length = len(concatenated_examples[list(examples.keys())[0]])\n","    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n","        # customize this part to your needs.\n","    total_length = (total_length // block_size) * block_size\n","    # Split by chunks of max_len.\n","    result = {\n","        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n","        for k, t in concatenated_examples.items()\n","    }\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1679769745978,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"X_dzpuU53Gd0","outputId":"648f5fdb-41f0-4ba1-be3f-a8c44d5b4133"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/under-tree___parquet/under-tree--labeled-multiple-choice-8214d50786758969/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-b04331c532286df4_*_of_00004.arrow\n"]}],"source":["data_lm = data_encoded.map(group_texts, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1679769745978,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"IYB43mhr3Gd0"},"outputs":[],"source":["data_dict = data_lm.train_test_split(test_size=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1679769746268,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"4uADL10h3Gd1","outputId":"9cc9ea47-a8bf-4d3c-8e4e-b25242a89966"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n"]}],"source":["from transformers import Trainer, TrainingArguments\n","\n","data_dict = data_dic\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',   \n","    evaluation_strategy='epoch',\n","    num_train_epochs=2\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":203,"status":"ok","timestamp":1679769884054,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"vSmuoDfL3Gd1"},"outputs":[],"source":["# default args are pretty good: https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments\n","data_dict = data_dict_copy.copy()\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=data_dict['train'],\n","    eval_dataset=data_dict['test']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"QhxNB4F_3Gd1","outputId":"9cdd92cf-88df-4c14-8a39-0745433b8694"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3' max='3836' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [   3/3836 00:27 < 29:41:17, 0.04 it/s, Epoch 0.00/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer.train()\n","trainer.save_model('result/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":4042,"status":"error","timestamp":1679769718961,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"5PtTQYoj-vx-","outputId":"53a02d1d-6495-4bbf-cf9f-7e4032d86083"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-51f5c7c180f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'torch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data_dict' is not defined"]}],"source":["import torch\n","from transformers import get_scheduler, AdamW\n","\n","\n","data_dict.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","train, test = data_dict['train'], data_dict['test']\n","train_loader, test_loader = torch.utils.data.DataLoader(train, batch_size=8, shuffle=True), torch.utils.data.DataLoader(test, batch_size=8)\n","accelerator = Accelerator()\n","train_loader, test_loader = accelerator.prepare(train_loader, test_loader)\n","\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","num_epochs = 3\n","num_training_steps = len(train) * num_epochs\n","scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","None"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1679769718967,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"Prxex15x-vx-"},"outputs":[],"source":["from tqdm import tqdm\n","\n","def train():\n","    # accelerator = Accelerator()\n","    model.train()\n","    progress_bar = tqdm(range(num_epochs * len(train_loader)))\n","    for epoch in range(num_epochs):\n","        for step, batch in enumerate(train_loader):\n","            outputs = model(**batch)\n","            loss = outputs.loss\n","            accelerator.backward(loss)\n","            optimizer.step()\n","            scheduler.step()\n","            optimizer.zero_grad()\n","            progress_bar.update(1)\n","            if step % 500 == 0:\n","                print(f'Epoch: {epoch}, Step: {step}, Loss: {loss}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1679769718967,"user":{"displayName":"Rodion Khvorostov","userId":"14168350354996550512"},"user_tz":-60},"id":"huVDdTzV-vx-"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13 (default, Sep 23 2022, 10:28:17) \n[GCC 9.4.0]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
